{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8qbMhoyZjKQVkExcGT3MO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DOLLARDEV05/AI-LAB/blob/main/Attention_is_All_You_Need/Transformers/single_head_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7VJMpX4pVY7F",
        "outputId": "623bc309-328e-4b1c-ada1-1bb9a686904a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['my', 'cat', 'is', 'lazy']\n",
            "Vocab: {'lazy': 0, 'cat': 1, 'is': 2, 'my': 3}\n",
            "Token IDs: [3 1 2 0]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "sentence = \"My cat is lazy\"\n",
        "\n",
        "tokens = sentence.lower().split()\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "vocab = {word: idx for idx, word in enumerate(set(tokens))}\n",
        "print(\"Vocab:\", vocab)\n",
        "\n",
        "token_ids = np.array([vocab[word] for word in tokens])\n",
        "print(\"Token IDs:\", token_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's create some embeddings!\n",
        "\n",
        "d_model = 4\n",
        "\n",
        "# this will create a random matrix of small float values with dimension being\n",
        "# rows = length of the sentence/token list, columns being the dimension we set\n",
        "# that is the d_model = 4 where this is a hyperparameter, and for single head\n",
        "# attention this is d_model = Q = K = V\n",
        "embedding = np.random.rand(len(tokens),d_model)\n",
        "\n",
        "print(embedding)"
      ],
      "metadata": {
        "id": "-3v1CdbtWc9C",
        "outputId": "0911474a-ce30-4e69-e1b7-e868614143d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.79093974 0.02522849 0.64786399 0.95843736]\n",
            " [0.70727585 0.82519675 0.53106664 0.97615182]\n",
            " [0.74865837 0.70274123 0.24756134 0.11911246]\n",
            " [0.85118147 0.94963237 0.08009344 0.68833727]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_token = np.array([embedding[vocab[token]] for token in tokens])\n",
        "print(embedding_token)"
      ],
      "metadata": {
        "id": "fMoIlxdIPhan",
        "outputId": "dcd91574-5cde-4b73-ef97-75973ece63db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.85118147 0.94963237 0.08009344 0.68833727]\n",
            " [0.70727585 0.82519675 0.53106664 0.97615182]\n",
            " [0.74865837 0.70274123 0.24756134 0.11911246]\n",
            " [0.79093974 0.02522849 0.64786399 0.95843736]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's convert the maths of positional encoding into code successful\n",
        "\n",
        "import math\n",
        "\n",
        "for embedding in range(len(embedding_token)):\n",
        "  for value in range(d_model):\n",
        "    if value % 2 == 0:\n",
        "      temp = math.sin(embedding/10000**((2*(value//2))/d_model))\n",
        "      embedding_token[embedding,value]=embedding_token[embedding,value]+temp\n",
        "    elif value % 2 == 1:\n",
        "      temp = math.cos(embedding/10000**((2*(value//2))/d_model))\n",
        "      embedding_token[embedding,value]=embedding_token[embedding,value]+temp\n",
        "    else:\n",
        "      print(\"error\")\n",
        "print(embedding_token)"
      ],
      "metadata": {
        "id": "4GnTjTGQ25aa",
        "outputId": "ac477d24-137e-4ded-e89a-d73df7cf1e1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.85118147  1.94963237  0.08009344  1.68833727]\n",
            " [ 1.54874683  1.36549906  0.54106647  1.97610182]\n",
            " [ 1.65795579  0.28659439  0.26756001  1.11891246]\n",
            " [ 0.93205975 -0.96476401  0.67785949  1.9579874 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = 0 // 2\n",
        "y = 1 // 2\n",
        "z = 2 // 2\n",
        "p = 3 // 2\n",
        "q = 4 // 2\n",
        "\n",
        "# how positional encoding uses floor division to have similar values given to the\n",
        "# sin and cos fuction to have pi/2 shifted sin and cos waves that also dipicts a\n",
        "# circle idk if this is necessary to mention here\n",
        "\n",
        "print(x,y,z,p,q)\n",
        "\n",
        "# was just showcasing where i was stuck in positional encoding and why it matter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sAVXWAssM0h",
        "outputId": "101bebb4-031d-42ea-c2b5-b711289501da"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0 1 1 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's work on making the weight matrix that will extract features from the\n",
        "# embedding matrix ! W_Q,W_K,W_V\n",
        "\n",
        "\n",
        "W_Q = np.random.rand(d_model,d_model)\n",
        "W_K = np.random.rand(d_model,d_model)\n",
        "W_V = np.random.rand(d_model,d_model)\n",
        "\n",
        "print(W_Q)\n",
        "print(W_K)\n",
        "print(W_V)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZHoI9NayTjz",
        "outputId": "7b65c1e3-a196-4bf5-cdcf-4ebf52e1e2fa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.81696593 0.56279898 0.66859006 0.38688357]\n",
            " [0.21019105 0.51028052 0.41529454 0.63794461]\n",
            " [0.93625725 0.28291135 0.43364866 0.48877707]\n",
            " [0.98563605 0.37907947 0.83791204 0.05933695]]\n",
            "[[0.25643168 0.50920873 0.90321555 0.8123113 ]\n",
            " [0.31801313 0.96442879 0.22835597 0.06321805]\n",
            " [0.57571892 0.33734735 0.83224125 0.8761615 ]\n",
            " [0.13091818 0.6655994  0.13136361 0.10669835]]\n",
            "[[0.78572169 0.48145457 0.98621154 0.35160185]\n",
            " [0.88870846 0.43048519 0.62888936 0.05948812]\n",
            " [0.59566161 0.2607628  0.84319599 0.92404155]\n",
            " [0.15342217 0.46801284 0.89791307 0.90106413]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiplying the weighted matrix with the embedded_token to get Q K V matrices\n",
        "\n",
        "\n",
        "Q = embedding_token @ W_Q\n",
        "K = embedding_token @ W_K\n",
        "V = embedding_token @ W_V\n",
        "\n",
        "print(Q,\"\\n\\n\",K,\"\\n\\n\\n\",V)\n",
        "\n",
        "# i used the ** 1/2 or **0.5 which is fine for scalers and one time operations\n",
        "# but its better to use np.sqrt() which is faster for sqrting whole arrays!\n",
        "# print((Q @ K.T)/d_model**(1/2))\n",
        "pre_softmax = (Q @ K.T)/np.sqrt(d_model)\n",
        "\n",
        "print(pre_softmax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFL33XoezneV",
        "outputId": "3c17630d-9386-4366-9294-fba5537b4bd8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.84425568 2.1365768  2.82817369 1.7123942 ]\n",
            " [4.00658368 2.47059417 3.4929933  1.85201421]\n",
            " [2.76807843 1.57919186 2.28109111 1.02143725]\n",
            " [3.12319012 0.96626896 2.15707872 0.19263579]] \n",
            "\n",
            " [[1.10542393 3.4644862  1.50245368 1.06499387]\n",
            " [1.40160425 3.60338154 2.42055779 2.02929716]\n",
            " [0.81681852 1.95565357 1.93259585 1.71870606]\n",
            " [0.57879471 1.07607611 1.44289215 1.49896059]] \n",
            "\n",
            "\n",
            " [[2.70818348 2.06014199 3.64906261 2.01056677]\n",
            " [3.0558849  2.39940941 4.61673256 2.90633561]\n",
            " [1.88843189 1.51504014 3.04562295 1.85543774]\n",
            " [0.57911917 1.1265516  2.64214913 2.66096448]]\n",
            "[[ 8.30956922 11.0030684   7.45523189  5.29646023]\n",
            " [10.10437865 13.36570871  9.01894522  6.39682288]\n",
            " [ 6.52302334  8.58224692  5.75667376  4.06197122]\n",
            " [ 5.12307068  6.73578061  4.47030627  3.12432514]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's recreate softmax from scratch using only numpy and convert these vectors\n",
        "# into attention scores that our model can use!\n",
        "\n"
      ],
      "metadata": {
        "id": "NCZT49Ea6jl9"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}